{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836a1e2e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46338c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and installs\n",
    "import transformers\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "# !pip install craft-text-detector\n",
    "import transformers\n",
    "from craft_text_detector import Craft\n",
    "import requests \n",
    "import torch\n",
    "import os, random\n",
    "from PIL import Image,ImageFilter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import imghdr\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "from string_grouper import match_strings, match_most_similar\n",
    "# !pip install pycountry\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeef3de",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set COLAB = False if running on SCC\n",
    "COLAB = False\n",
    "\n",
    "#suppressing all the huggingface warnings\n",
    "SUPPRESS = True\n",
    "if SUPPRESS:\n",
    "    from transformers.utils import logging\n",
    "    logging.set_verbosity(40)\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive',force_remount = True)\n",
    "    workdir = '/content/gdrive/MyDrive/testing-trocr'\n",
    "    output_dir_craft = '/content/gdrive/MyDrive/craft/'\n",
    "else:\n",
    "    workdir = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/scraped-data/drago_testdata' # update this to the desired directory on scc\n",
    "    output_dir_craft = '/projectnb/sparkgrp/colejh/craft'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99c22b",
   "metadata": {},
   "source": [
    "# Running craft and saving the segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the CRAFT model\n",
    "craft = Craft(output_dir = output_dir_craft,export_extra = False, text_threshold = .8,link_threshold = .6, crop_type=\"poly\",low_text = .5,cuda = True)\n",
    "\n",
    "# CRAFT on images to get bounding boxes\n",
    "images = []\n",
    "corrupted_images = []\n",
    "no_segmentations = []\n",
    "boxes = {}\n",
    "count= 0\n",
    "img_name = []\n",
    "box = []\n",
    "file_types = (\".jpg\", \".jpeg\",\".png\")\n",
    "for filename in tqdm(os.listdir(workdir)):\n",
    "    if filename.endswith(file_types):\n",
    "        image = workdir+'/'+filename\n",
    "        try:\n",
    "            img = Image.open(image) \n",
    "            img.verify() # Check that the image is valid\n",
    "            bounding_areas = craft.detect_text(image)\n",
    "            if not bounding_areas: #check that a segmentation was found\n",
    "                no_segmentations.append(image)\n",
    "            else:\n",
    "                images.append(image)\n",
    "                boxes[image] = bounding_areas['boxes']\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupted_images.append(image)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255c2b3",
   "metadata": {},
   "source": [
    "# Getting all the segemnted images into a dataloader, and loading model and processor for trocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting empty folders\n",
    "root = output_dir_craft\n",
    "folders = list(os.walk(root))[1:]\n",
    "deleted = []\n",
    "for folder in folders:\n",
    "    # folder example: ('FOLDER/3', [], ['file'])\n",
    "    if not folder[2]:\n",
    "        deleted.append(folder)\n",
    "        os.rmdir(folder[0])\n",
    "        \n",
    "# Setting up the Tr-OCR model (using base model currently, large takes much longer)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\") \n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n",
    "\n",
    "# Use all available gpu's\n",
    "model_gpu= nn.DataParallel(model,list(range(torch.cuda.device_count()))).to(device)\n",
    "\n",
    "# Dataloader for working with gpu's\n",
    "trainset = datasets.ImageFolder(output_dir_craft, transform = processor)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)# for i, data in enumerate(trainloader):\n",
    "\n",
    "# For matching words to image\n",
    "filenames = [s.replace('_crops', '') for s in list(trainset.class_to_idx)]\n",
    "word_log_dic = {k: v for k,v in enumerate(filenames)}\n",
    "words_identified = {k: [] for v,k in enumerate(filenames)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/projectnb/sparkgrp/colejh/saved_results/'\n",
    "# save filenames\n",
    "with open(r'/projectnb/sparkgrp/colejh/saved_results/filenames.txt', 'w') as fp:\n",
    "    for item in filenames:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a47e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word_log_dic and words_identified\n",
    "with open(save_dir+'word_log_dic.json', 'w') as fp:\n",
    "    json.dump(word_log_dic, fp)\n",
    "with open(save_dir+'words_identified.json', 'w') as fp:\n",
    "    json.dump(words_identified, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b47fc7",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f87b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yoinked https://github.com/rsommerfeld/trocr/blob/main/src/scripts.py\n",
    "# For later use if we want to use the confidence scores from the model \n",
    "def get_confidence_scores(generated_ids):\n",
    "    # Get raw logits, with shape (examples,tokens,token_vals)\n",
    "    logits = generated_ids.scores\n",
    "    logits = torch.stack(list(logits),dim=1)\n",
    "\n",
    "    # Transform logits to softmax and keep only the highest (chosen) p for each token\n",
    "    logit_probs = F.softmax(logits, dim=2)\n",
    "    char_probs = logit_probs.max(dim=2)[0]\n",
    "\n",
    "    # Only tokens of val>2 should influence the confidence. Thus, set probabilities to 1 for tokens 0-2\n",
    "    mask = generated_ids.sequences[:,:-1] > 2\n",
    "    char_probs[mask] = 1\n",
    "\n",
    "    # Confidence of each example is cumulative product of token probs\n",
    "    batch_confidence_scores = char_probs.cumprod(dim=1)[:, -1]\n",
    "    return [v.item() for v in batch_confidence_scores]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_craft_seg(model,trainloader):\n",
    "    results = []\n",
    "    confidence = []\n",
    "    label = []\n",
    "\n",
    "    model_gpu.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx,data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "            images, labels = data\n",
    "            images, labels = images['pixel_values'][0].to(device), labels.to(device)\n",
    "\n",
    "            decoded = model_gpu.module.generate(images,return_dict_in_generate = True, output_scores = True) \n",
    "            final_values = processor.batch_decode(decoded.sequences, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "            confidences = get_confidence_scores(decoded)\n",
    "\n",
    "            for idx,value in enumerate(labels.cpu().numpy()):\n",
    "#           if confidences[idx]>.8: # to cull some of the really terrible guesses, probably want to do this in the search function instead\n",
    "                words_identified[word_log_dic[value]].append(final_values[idx])\n",
    "            \n",
    "            results.extend(final_values)\n",
    "            confidence.extend(confidences)\n",
    "            label.extend(labels.cpu().numpy())\n",
    "\n",
    "    return results,confidence,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the outputs\n",
    "results,confidence,labels = evaluate_craft_seg(model,trainloader)\n",
    "#Saving all the outputs \n",
    "df = pd.DataFrame(list(zip(results,confidence,labels)),columns = ['Results','Confidence','Labels'])\n",
    "df.to_pickle(save_dir+'full_results.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ed287",
   "metadata": {},
   "source": [
    "# Loading the full species, taxon, genus, countries and subdivsion information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the string matching files\n",
    "ALL_SPECIES_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_species.pkl'\n",
    "ALL_GENUS_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_genus.pkl'\n",
    "ALL_TAXON_FILE = '/usr3/graduate/colejh/corpus_taxon.txt'\n",
    "species = pd.Series(list(pd.read_pickle(ALL_SPECIES_FILE)))\n",
    "genus = pd.Series(list(pd.read_pickle(ALL_GENUS_FILE)))\n",
    "taxon = pd.read_csv(ALL_TAXON_FILE,delimiter = \"\\t\", names=[\"Taxon\"]).squeeze()\n",
    "\n",
    "countries = []\n",
    "for country in list(pycountry.countries):\n",
    "    countries.append(country)\n",
    "\n",
    "\n",
    "subdivisions_dict = {}\n",
    "subdivisions = []\n",
    "for subdivision in pycountry.subdivisions:\n",
    "    subdivisions.append(subdivision.name)\n",
    "    subdivisions_dict[subdivision.name] = pycountry.countries.get(alpha_2 = subdivision.country_code).name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c208af7",
   "metadata": {},
   "source": [
    "# Functions to pick the best match from each set of species, genus, taxon, country, and subdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the minimum similarity percentage you want (can also be set in pooled_match)\n",
    "def matches_above_x(df,x):\n",
    "    return df.loc[df['similarity']>=.75]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(main,comparison_file,minimum_similarity):\n",
    "     # Function takes a main file containing strings, a comparison file to match against main,\n",
    "     #  and a minimum similarity confidence level. Returns a list of matches based on similarity.\n",
    "\n",
    "    if not isinstance(comparison_file, pd.Series):\n",
    "\n",
    "        comparison_file = pd.Series(comparison_file)\n",
    "\n",
    "    matches = match_strings(main,comparison_file,n_blocks = 'guess',min_similarity = minimum_similarity,max_n_matches = 1)\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade67d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_score_per_image(df,labels,minimum_similarity):\n",
    "    # Getting the highest score for each individual image \n",
    "    index_to_labels = df.copy()\n",
    "    for a in index_to_labels.right_index.unique():\n",
    "        index_to_labels.loc[index_to_labels['right_index'] == a, 'right_index'] = labels[a]\n",
    "    unique_labels = index_to_labels.loc[index_to_labels.groupby('right_index')['similarity'].idxmax()]\n",
    "\n",
    "\n",
    "    return unique_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ece176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_match(comparison_file,labels, minimum_similarity = .7,**kwargs):\n",
    "    # Take in any number of files containing strings to match against and return a dictionary\n",
    "    # with keys the same name as input and values as the dataframe with matching information\n",
    "   \n",
    "    corpus_list = []\n",
    "    corpus_name = []\n",
    "    \n",
    "    for k,v in kwargs.items():\n",
    "    # Convert to series (string-grouper requires this type), will work if input is list, array, or series\n",
    "        if not isinstance(v, pd.Series):\n",
    "            v = pd.Series(v)\n",
    "        corpus_list.append(v)\n",
    "        corpus_name.append(k)\n",
    "    \n",
    "    if not isinstance(comparison_file, pd.Series):\n",
    "        comparison_file = pd.Series(comparison_file)\n",
    "\n",
    "    func = partial(match, comparison_file = comparison_file,  minimum_similarity = minimum_similarity)\n",
    "    pool = multiprocessing.Pool()\n",
    "   \n",
    "    result_dic = {}\n",
    "    for i,result in enumerate(pool.map(func,corpus_list)):\n",
    "        result.columns.values[1] = corpus_name[i]+' Corpus'\n",
    "        result.columns.values[3] = \"Predictions\"\n",
    "        result = result.drop('left_index', axis=1)\n",
    "        result = highest_score_per_image(result,labels)\n",
    "        result_dic[corpus_name[i]] = result\n",
    "   \n",
    "    return result_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b98d89",
   "metadata": {},
   "source": [
    " # Performing the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to string-grouper all need to be series format\n",
    "results_series = pd.Series(results)\n",
    "\n",
    "#running the matching against all files\n",
    "minimum_similarity = .01 #arbitrary, set here to get every prediction, likely want to set this quite higher\n",
    "start = time.time()\n",
    "results = pooled_match(results_series,labels,minimum_similarity =.01,Taxon = taxon,Species = species,Genus = genus,Countries = countries,Subdivisions = subdivisions)\n",
    "end = time.time()\n",
    "print('Time to match all strings: ',end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784b028",
   "metadata": {},
   "source": [
    "# Reading in the ground truth files for tested images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6841f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the ground truth values\n",
    "gt_t = workdir+'/taxon_gt.txt'\n",
    "Taxon_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_t) }\n",
    "\n",
    "gt_g = workdir+'/geography_gt.txt'\n",
    "Geography_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_g) }\n",
    "\n",
    "gt_c = workdir+'/collector_gt.txt'\n",
    "Collector_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_c) }\n",
    "\n",
    "comparison_file = {\"Taxon\":Taxon_truth,\"Geography\":Geography_truth,\"Collector\":Collector_truth}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f92d2",
   "metadata": {},
   "source": [
    "# Checking each result against the ground truth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606804be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fancy print\n",
    " class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92954ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k,v in all_matches.items():    \n",
    "    # need to add in the check for other species names, quite a few would match\n",
    "    prediction_and_imagenumber = list(zip(v[k+' Corpus'], v.right_index))\n",
    "    print('Evaluation for',k)\n",
    "    for idx,(prediction,image_number) in enumerate(prediction_and_imagenumber):\n",
    "        try:\n",
    "            image = word_log_dic[image_number]\n",
    "            gt = comparison_file[k][image]\n",
    "            if gt == prediction:\n",
    "                count +=1\n",
    "                print(gt,\"||\",prediction,'||',image,'||',v['similarity'][idx])\n",
    "            else:\n",
    "                print(color.RED+gt+\"||\"+prediction+'||'+str(image)+'||'+str(v['similarity'][idx])+color.END)\n",
    "        except KeyError as e:\n",
    "            print(\"Ground Truth Not Found for:\",word_log_dic[image_number])\n",
    "    \n",
    "    acc = count/len(v)\n",
    "    print(color.BOLD+\"Accuracy on Predicted:\"+str(acc)+color.END)\n",
    "    print(color.BOLD+\"Total accuracy: \"+str(count/len(filenames))+color.END)\n",
    "    print(color.BOLD+\"Total Guessed:\"+str(len(prediction_and_imagenumber))+color.END)\n",
    "    print('\\n\\n********************************\\n\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

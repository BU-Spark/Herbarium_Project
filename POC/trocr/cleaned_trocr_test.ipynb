{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836a1e2e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46338c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and installs\n",
    "import transformers\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "# !pip install craft-text-detector\n",
    "import transformers\n",
    "from craft_text_detector import Craft # Need to edit the saving function to prepend 0's\n",
    "import requests \n",
    "import torch\n",
    "import os, random\n",
    "from PIL import Image,ImageFilter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import imghdr\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "# from string_grouper import match_strings, match_most_similar\n",
    "# !pip install pycountry\n",
    "import pycountry\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import trocr\n",
    "import matching\n",
    "import predictions\n",
    "import results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeef3de",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing all the huggingface warnings\n",
    "SUPPRESS = True\n",
    "if SUPPRESS:\n",
    "    from transformers.utils import logging\n",
    "    logging.set_verbosity(40)\n",
    "# Turning off this warning, isn't relevant for this application\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)\n",
    "\n",
    "# Location of images\n",
    "workdir = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/TROCR_Training/goodfiles/' # update this to the desired directory on scc\n",
    "# Location of the segmentations\n",
    "output_dir_craft = '/projectnb/sparkgrp/colejh/goodfilescraft'\n",
    "# Location to save all output files\n",
    "save_dir = '/projectnb/sparkgrp/colejh/saved_results2/'\n",
    "# For ground truth labels \n",
    "workdir2 = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/scraped-data/drago_testdata/gt_labels' # update this to the desired directory on scc\n",
    "# Corpus files\n",
    "ALL_SPECIES_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_species.pkl'\n",
    "ALL_GENUS_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_genus.pkl'\n",
    "ALL_TAXON_FILE = '/usr3/graduate/colejh/corpus_taxon.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99c22b",
   "metadata": {},
   "source": [
    "# Running craft and saving the segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the CRAFT model\n",
    "craft = Craft(output_dir = output_dir_craft,export_extra = False, text_threshold = .7,link_threshold = .4, crop_type=\"poly\",low_text = .3,cuda = True)\n",
    "\n",
    "# CRAFT on images to get bounding boxes\n",
    "images = []\n",
    "corrupted_images = []\n",
    "no_segmentations = []\n",
    "boxes = {}\n",
    "count= 0\n",
    "img_name = []\n",
    "box = []\n",
    "file_types = (\".jpg\", \".jpeg\",\".png\")\n",
    "for filename in tqdm(sorted(os.listdir(workdir))):\n",
    "    if filename.endswith(file_types):\n",
    "        image = workdir+filename\n",
    "        try:\n",
    "            img = Image.open(image) \n",
    "            img.verify() # Check that the image is valid\n",
    "            bounding_areas = craft.detect_text(image)\n",
    "            if len(bounding_areas['boxes']): #check that a segmentation was found\n",
    "                images.append(image)\n",
    "                boxes[image] = bounding_areas['boxes']\n",
    "                \n",
    "            else:\n",
    "                no_segmentations.append(image)\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupted_images.append(image)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255c2b3",
   "metadata": {},
   "source": [
    "# Getting all the segemnted images into a dataloader, and loading model and processor for trocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting empty folders, which occurs if some of the images get no segementation from CRAFT\n",
    "root = output_dir_craft\n",
    "folders = list(os.walk(root))[1:]\n",
    "deleted = []\n",
    "for folder in folders:\n",
    "    if not folder[2]:\n",
    "        deleted.append(folder)\n",
    "        os.rmdir(folder[0])\n",
    "        \n",
    "# Setting up the Tr-OCR model and processor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\") \n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n",
    "\n",
    "# Use all available gpu's\n",
    "model_gpu= nn.DataParallel(model,list(range(torch.cuda.device_count()))).to(device)\n",
    "\n",
    "# Dataloader for working with gpu's\n",
    "trainset = datasets.ImageFolder(output_dir_craft, transform = processor)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=False)\n",
    "\n",
    "# For matching words to image\n",
    "filenames = [s.replace('_crops', '') for s in list(trainset.class_to_idx)]\n",
    "\n",
    "# For matching the image name with the label name\n",
    "word_log_dic = {k: v for k,v in enumerate(filenames)}\n",
    "# For matching the image name with the transriptions\n",
    "words_identified = {k: [] for v,k in enumerate(filenames)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17dc11",
   "metadata": {},
   "source": [
    "# Saving the filenames, word_log_dic and words_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filenames\n",
    "with open(save_dir+'filenames.txt', 'w') as fp:\n",
    "    for item in filenames:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "# Save word_log_dic \n",
    "with open(save_dir+'word_log_dic.json', 'w') as fp:\n",
    "    json.dump(word_log_dic, fp)\n",
    "# Save words_identified\n",
    "with open(save_dir+'words_identified.json', 'w') as fp:\n",
    "    json.dump(words_identified, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b47fc7",
   "metadata": {},
   "source": [
    "# Running Tr-OCR on the Segmented Images from Craft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the outputs\n",
    "results,confidence,labels = trocr.evaluate_craft_seg(model,processor, words_identified,word_log_dic,testloader,device)\n",
    "#Saving all the outputs in dataframe\n",
    "df = pd.DataFrame(list(zip(results,confidence,labels)),columns = ['Results','Confidence','Labels'])\n",
    "df.to_pickle(save_dir+'full_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First part of final csv with results, confidence level from tr-ocr, and label\n",
    "combined_df = trocr.combine_by_label(df)\n",
    "\n",
    "# Adding the image path and all bounding boxes \n",
    "\n",
    "df_dictionary = pd.DataFrame(boxes.items(), columns=['Image_Path', 'Bounding_Boxes'])\n",
    "combined_df = pd.concat([combined_df, df_dictionary], axis=1, join='inner')\n",
    "display(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f663f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save intermediate file\n",
    "combined_df.to_pickle(save_dir+'/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfeb18e",
   "metadata": {},
   "source": [
    "# Get the Bigrams for all transcriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee34c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column which contains all bigrams from the transcription, with an associated index for each bigram\n",
    "bigram_df = combined_df.copy()\n",
    "\n",
    "bigram_df['Bigrams'] = bigram_df['Transcription'].str.join(' ').str.split(' ')\n",
    "\n",
    "bigram_df['Bigrams'] = bigram_df['Bigrams'].apply(lambda lst: [lst[i:i+2] for i in range(len(lst) - 1)]).apply(lambda sublists: [' '.join(sublist) for sublist in sublists])\n",
    "bigram_df['Bigram_idx'] = bigram_df.apply(matching.bigram_indices, axis=1)\n",
    "\n",
    "# Associating all biagrams with their respective image\n",
    "bigram_idx = []\n",
    "for i in range(len(bigram_df)):\n",
    "    for j in range(len(bigram_df.loc[i, 'Bigrams'])):\n",
    "        bigram_idx.append((i))\n",
    "bigram_idx = pd.Series(bigram_idx)\n",
    "\n",
    "# Getting the bigrams as individual strings\n",
    "results = pd.Series(bigram_df['Bigrams'].explode().reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ed287",
   "metadata": {},
   "source": [
    "# Loading the full species, taxon, genus, countries and subdivsion information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = pd.Series(list(pd.read_pickle(ALL_SPECIES_FILE)))\n",
    "genus = pd.Series(list(pd.read_pickle(ALL_GENUS_FILE)))\n",
    "taxon = pd.read_csv(ALL_TAXON_FILE,delimiter = \"\\t\", names=[\"Taxon\"]).squeeze()\n",
    "\n",
    "# All countries and subdivisions for matching \n",
    "countries = []\n",
    "for country in list(pycountry.countries):\n",
    "    countries.append(country)\n",
    "\n",
    "\n",
    "subdivisions_dict = {}\n",
    "subdivisions = []\n",
    "for subdivision in pycountry.subdivisions:\n",
    "    subdivisions.append(subdivision.name)\n",
    "    subdivisions_dict[subdivision.name] = pycountry.countries.get(alpha_2 = subdivision.country_code).name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b98d89",
   "metadata": {},
   "source": [
    " # Performing the String Matching against all Corpus Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the matching against all files\n",
    "minimum_similarity = .01 #arbitrary, set here to get every prediction, likely want to set this quite a bit higher\n",
    "start = time.time()\n",
    "all_matches = matching.pooled_match(results,bigram_idx,minimum_similarity =.01,Taxon = taxon,Species = species,Genus = genus,Countries = countries,Subdivisions = subdivisions)\n",
    "end = time.time()\n",
    "print('Time to match all strings: ',end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all_matches pickle\n",
    "with open(save_dir + 'all_matches.pkl', 'wb') as f:\n",
    "    pickle.dump(all_matches, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f167c",
   "metadata": {},
   "source": [
    "# Final Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the final dataframe with all output information\n",
    "final_df = bigram_df.copy()\n",
    "\n",
    "for k,v in all_matches.items():\n",
    "    final_df = pd.merge(final_df,v[['right_index','Predictions','similarity',k+'_Corpus']],how = 'left',\n",
    "                    left_on = 'Labels', right_on = 'right_index')\n",
    "    # Rename the predictions, similarity, and corpus columns\n",
    "    final_df = final_df.rename(columns = {'Predictions':k+'_Prediction_String','similarity':k+'_Similarity',k+'_Corpus':k+'_Prediction'})\n",
    "    # Drop the right_index column\n",
    "    final_df = final_df.drop(columns = ['right_index'])\n",
    "    # Dealing with the case where there is no match\n",
    "    final_df[k+'_Index_Location'] = [x[0].index(x[1]) if x[1] in x[0] else 'No Match Found' for x in zip(final_df['Bigrams'], final_df[k+'_Prediction_String'])]\n",
    "\n",
    "# Save the final dataframe\n",
    "final_df.to_pickle(save_dir + 'final_df.pkl')\n",
    "# Display final dataframe\n",
    "display(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784b028",
   "metadata": {},
   "source": [
    "# Reading in the ground truth files for tested images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6841f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the ground truth values\n",
    "\n",
    "gt_t = workdir2+'/taxon_gt.txt'\n",
    "Taxon_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_t) }\n",
    "\n",
    "gt_g = workdir2+'/geography_gt.txt'\n",
    "Geography_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_g) }\n",
    "\n",
    "gt_c = workdir2+'/collector_gt.txt'\n",
    "Collector_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_c) }\n",
    "\n",
    "comparison_file = {\"Taxon\":Taxon_truth,\"Countries\":Geography_truth,\"Collector\":Collector_truth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9312e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in synonym dictionary \n",
    "syn_location = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/synonym-matching/output/'\n",
    "syn_pure = pickle.load(open(syn_location+'syn_pure.pkl','rb'))\n",
    "\n",
    "#adding United States to dictionary \n",
    "syn_pure['united states'] = 'United States of America'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f92d2",
   "metadata": {},
   "source": [
    "# Checking Accuracy Against all Ground Truth Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2921444",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.print_prediction(all_matches,comparison_file,word_log_dic,syn_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb676d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the accuracy of the model at various similarity thresholds\n",
    "sim = []\n",
    "acc_pred = []\n",
    "total_acc = []\n",
    "types = []\n",
    "s_match = []\n",
    "co = []\n",
    "for i in range(1,10):\n",
    "    min_simil = i/10\n",
    "    print(predictions.color.BOLD+\"Minimum Similarity: \"+str(min_simil)+predictions.color.END)\n",
    "    a,b,c,d,e= predictions.check_accuracy(all_matches,syn_pure,word_log_dic,comparison_file,min_simil)\n",
    "    sim.append(min_simil)\n",
    "    acc_pred.append(a)\n",
    "    total_acc.append(b)\n",
    "    s_match.append(c)\n",
    "    types.append(d)\n",
    "    co.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the accuracy of the model at various similarity thresholds for Taxon and Geography\n",
    "tlist = list(zip(*acc_pred))\n",
    "tlist2 = list(zip(*total_acc))\n",
    "tlist3 = list(zip(*s_match))\n",
    "tlist4 = list(zip(*types))\n",
    "tlist5 = list(zip(*co))\n",
    "df = pd.DataFrame({'sim':sim,types[0][0]+' Number Predicted':tlist5[0],types[0][1]+' Number Predicted':tlist5[1], types[0][0]+' Accuracy Predicted':tlist[0],types[0][1]+' Accuracy Predicted':tlist[1],types[0][0]+' Total Accuracy Predicted':tlist2[0],types[0][1]+' Total Accuracy Predicted':tlist2[1],types[0][0]+' Synonym Matches':tlist3[0],types[0][1]+' Synonym Matches':tlist3[1]})\n",
    "df = df[['sim',types[0][0]+' Number Predicted',types[0][0]+' Accuracy Predicted',types[0][0]+' Total Accuracy Predicted',types[0][0]+' Synonym Matches',types[0][1]+' Number Predicted',types[0][1]+' Accuracy Predicted',types[0][1]+' Total Accuracy Predicted',types[0][1]+' Synonym Matches']]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b651ac9",
   "metadata": {},
   "source": [
    "# Displaying the Bounding Box and associated prediciton, colored by similarity confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f57c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random image from the test set\n",
    "random_label = random.randint(0, final_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94241019",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.display_image(final_df,all_matches,Taxon_truth,Geography_truth,word_log_dic,random_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b650c",
   "metadata": {},
   "source": [
    "# Displaying each bounding box with its associated transcription and transcription confidence, colored by transcription confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da74cdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interesting = [22,43,89,200]\n",
    "for label in interesting:\n",
    "    print('GT: '+Taxon_truth[word_log_dic[label]])\n",
    "    results.bounding_confidence_text(final_df,Taxon_truth,word_log_dic,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44182a",
   "metadata": {},
   "source": [
    "# All bounding boxes for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f030c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.all_boxes(final_df,label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1084cc30a0beff5f5a336ac1440c1980742df576b417f0ade42be5b6e50918a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

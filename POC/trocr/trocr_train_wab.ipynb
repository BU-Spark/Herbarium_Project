{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Getting all the models off my home directory for space concerns\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/projectnb/sparkgrp/colejh'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e20ed6",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install jiwer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric\n",
    "from transformers import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b155d7",
   "metadata": {},
   "source": [
    "# Supressing Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd342d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppressing all the huggingface warnings\n",
    "SUPPRESS = True\n",
    "if SUPPRESS:\n",
    "    from transformers.utils import logging\n",
    "    logging.set_verbosity(40)\n",
    "\n",
    "#others\n",
    "#ignoring UserWarning and FutureWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da534037",
   "metadata": {},
   "source": [
    "# Dataset preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the training file into a DataFrame\n",
    "IAM_lines = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/tesseract-training/training/IAM/gt/lines/'\n",
    "IAM_words = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/tesseract-training/training/IAM/gt/words/'\n",
    "IAM_sentences = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/tesseract-training/training/IAM/gt/sentences/'\n",
    "\n",
    "model_directory = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/TROCR_Training/'\n",
    "# All files and directories ending with .txt and that don't begin with a dot:\n",
    "def get_lists(directory,directory_percentage):\n",
    "    image_list = glob.glob(directory+\"*.png\")\n",
    "\n",
    "    text_list = []\n",
    "    for image in image_list:\n",
    "        text_list.extend(open(image.split('.')[0]+'.gt.txt','r').read().splitlines())\n",
    "\n",
    "    # Take a random percentage of the data\n",
    "    image_list, text_list = zip(*random.sample(list(zip(image_list, text_list)), round(directory_percentage/100*len(image_list))))\n",
    "    return image_list,text_list\n",
    "\n",
    "\n",
    "# Taken from https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TrOCR/Fine_tune_TrOCR_on_IAM_Handwriting_Database_using_native_PyTorch.ipynb\n",
    "class IAMDataset(Dataset):\n",
    "    def __init__(self, df, processor, max_target_length=128):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        image = self.df['image'][idx]\n",
    "        text = self.df['text'][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        image = Image.open(image).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        # add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\", \n",
    "                                          max_length=self.max_target_length).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding\n",
    "\n",
    "\n",
    "image_list = []\n",
    "text_list = []\n",
    "lines_percentage = 1\n",
    "words_percentage = 5\n",
    "sentences_percentage = 1\n",
    "for directory,percentage in zip([IAM_lines, IAM_words, IAM_sentences],[lines_percentage, words_percentage, sentences_percentage]):\n",
    "    images,text = get_lists(directory,percentage)\n",
    "    image_list.extend(images)\n",
    "    text_list.extend(text)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'image':image_list,'text':text_list})\n",
    "\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5774735",
   "metadata": {},
   "source": [
    "# All Possible Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['microsoft/trocr-base-printed',\n",
    "              'microsoft/trocr-base-handwritten',\n",
    "              'microsoft/trocr-large-handwritten',\n",
    "              'microsoft/trocr-small-handwritten',\n",
    "              'microsoft/trocr-large-printed',\n",
    "              'microsoft/trocr-base-stage1',\n",
    "              'microsoft/trocr-small-printed',\n",
    "              'microsoft/trocr-small-stage1',\n",
    "              'microsoft/trocr-base-str',\n",
    "              'microsoft/trocr-large-str',\n",
    "              'microsoft/trocr-large-stage1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e30be",
   "metadata": {},
   "source": [
    "# Full Training/Logging for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803bab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in all_models:\n",
    "    # New run for each model \n",
    "    \n",
    "    run = wandb.init(reinit = True,name = model_name.split('/')[1], project = \"Testing-Tr-OCR\")\n",
    "\n",
    "    #Loading model and processor \n",
    "    processor = TrOCRProcessor.from_pretrained(model_name) \n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "    # Checking if gpu is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #Putting the model on the GPU\n",
    "    model= nn.DataParallel(model,list(range(torch.cuda.device_count()))).to(device)\n",
    "\n",
    "\n",
    "    # Datasets and dataloaders for train validation\n",
    "    train_dataset = IAMDataset(df=train_df,processor=processor)\n",
    "    val_dataset = IAMDataset(df=val_df,processor=processor)\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=4)\n",
    "\n",
    "    # set special tokens used for creating the decoder_input_ids from the labels\n",
    "    model.module.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "    model.module.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "    # make sure vocab size is set correctly\n",
    "    model.module.config.vocab_size = model.module.config.decoder.vocab_size\n",
    "\n",
    "    # set beam search parameters\n",
    "    model.module.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "    model.module.config.max_length = 64\n",
    "    model.module.config.early_stopping = True\n",
    "    model.module.config.no_repeat_ngram_size = 3\n",
    "    model.module.config.length_penalty = 2.0\n",
    "    model.module.config.num_beams = 4\n",
    "\n",
    "    # Character error rate calculation\n",
    "    cer_metric = load_metric(\"cer\")\n",
    "\n",
    "    def compute_cer(pred_ids, label_ids):\n",
    "        pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "        label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "        return cer\n",
    "\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "    # Main Training Loop\n",
    "    avg_train_loss = []\n",
    "    avg_val_cer = []\n",
    "    last_val = float('inf')\n",
    "    min_val = float('inf')\n",
    "    patience = 3\n",
    "    EPOCHS = 5\n",
    "    counter = 0\n",
    "    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += torch.sum(loss).detach().cpu().numpy()\n",
    "        # Save loss locally\n",
    "        current_loss = train_loss/len(train_dataloader)\n",
    "        avg_train_loss.append(current_loss)\n",
    "        print(f\"Loss after epoch {epoch+1}:\", current_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        valid_cer = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader):\n",
    "                # run batch generation\n",
    "                outputs = model.module.generate(batch['pixel_values'].to(device))\n",
    "                # compute metrics\n",
    "                cer = compute_cer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
    "                valid_cer += cer \n",
    "\n",
    "\n",
    "            current_val = valid_cer/len(val_dataloader)\n",
    "            # Logging values\n",
    "            wandb.log({\"Test/Loss\": current_loss, \"Character-Error-Rate\": current_val}, step=epoch)\n",
    "\n",
    "            # If vaildation certainty decreases for patience epochs, stop training\n",
    "            # Save if new best model\n",
    "            if current_val > last_val:\n",
    "                counter += 1\n",
    "                last_val = current_val\n",
    "                if counter == patience:\n",
    "                    print('Validation CER reduced has increased for {} epochs, ending training...'.format(patience))\n",
    "                    avg_val_cer.append(last_val)\n",
    "                    run.finish()\n",
    "                    break\n",
    "            else:\n",
    "                counter = 0\n",
    "                if current_val<min_val:\n",
    "                    min_val = current_val\n",
    "                    # saving the best model so far\n",
    "                    torch.save(model.state_dict(), model_directory + model_name.split('/')[1]+'best_model.pt')\n",
    "            last_val = current_val\n",
    "\n",
    "        avg_val_cer.append(last_val)\n",
    "        print(\"Validation CER:\", last_val)\n",
    "    run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836a1e2e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46338c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "# Third-party library imports\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from craft_text_detector import Craft # Need to edit the saving function to prepend 0's\n",
    "from torchvision import datasets\n",
    "\n",
    "import taxonerd\n",
    "from taxonerd import TaxoNERD\n",
    "import spacy\n",
    "\n",
    "# Local application/library specific imports\n",
    "import trocr\n",
    "import detr\n",
    "\n",
    "# from importlib import reload\n",
    "# reload(detr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeef3de",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing all the huggingface warnings\n",
    "SUPPRESS = True\n",
    "if SUPPRESS:\n",
    "    from transformers.utils import logging\n",
    "    logging.set_verbosity(40)\n",
    "# Turning off this warning, isn't relevant for this application\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)\n",
    "\n",
    "# Location of input images\n",
    "inputdir = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/TROCR_Training/goodfiles/'\n",
    "# Location of images after label extraction (also input directory to CRAFT)\n",
    "# workdir = inputdir\n",
    "workdir = '/projectnb/sparkgrp/ml-herbarium-grp/summer2023/kabilanm/ml-herbarium/trocr/label-extraction/data/label-extraction-intermediate-files/' # update this to the desired directory on scc\n",
    "\n",
    "# Location of the segmentations\n",
    "output_dir_craft = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/craft_output_files/'\n",
    "# Location to save all output files\n",
    "save_dir = '/usr4/ds549/kabilanm/saved_results/'\n",
    "# For ground truth labels \n",
    "workdir2 = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/scraped-data/drago_testdata/gt_labels' # update this to the desired directory on scc\n",
    "\n",
    "# Corpus files\n",
    "ALL_SPECIES_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_species.pkl'\n",
    "ALL_GENUS_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_genus.pkl'\n",
    "# ALL_TAXON_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-new/ml-herbarium/corpus/corpus_taxon/corpus_taxon.txt'\n",
    "ALL_TAXON_FILE = '/usr4/ds549/kabilanm/ml-herbarium/corpus/corpus_taxon/corpus_taxon.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f86ba-7921-47ca-8007-19a8d9f3856a",
   "metadata": {},
   "source": [
    "# Running DETR to extract labels from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9feb0e5-6621-49a3-9c7e-fa3c9c3f49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DETR for inference (adopted from Freddie (https://github.com/freddiev4/comp-vision-scripts/blob/main/object-detection/detr.py))\n",
    "detr_model = 'KabilanM/detr-label-extraction'\n",
    "# The DETR model returns the bounding boxes of the lables indentified from the images\n",
    "# We will utilize the bounding boxes to rank lables in the downstream task\n",
    "label_bboxes = detr.run(inputdir, detr_model, workdir)\n",
    "\n",
    "# Save the label bounding boxes into a pickle file\n",
    "pickle.dump(label_bboxes, open(save_dir+\"label_boxes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360402c5-42aa-4500-b05f-f2fab0c7e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 251\n",
      "Number of images with bounding boxes: 242\n"
     ]
    }
   ],
   "source": [
    "# we remove images with no bounding boxes found\n",
    "label_bboxes = pickle.load(open(save_dir+\"label_boxes.pkl\", \"rb\"))\n",
    "keys_to_remove = []\n",
    "\n",
    "print(f\"Total number of images: {len(label_bboxes)}\")\n",
    "\n",
    "for key, value in label_bboxes.items():\n",
    "    if(len(value) == 0):\n",
    "        keys_to_remove.append(key)\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    label_bboxes.pop(key)\n",
    "\n",
    "print(f\"Number of images with bounding boxes: {len(label_bboxes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5f7eb5-6443-4bf8-a96a-189999eebee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3356834058.jpg',\n",
       " '1998550976.jpg',\n",
       " '3467354375.jpg',\n",
       " '3111515383.jpg',\n",
       " '2446819762.jpg',\n",
       " '3341239321.jpg',\n",
       " '1146138679.jpg',\n",
       " '1212567865.jpg',\n",
       " '1146376618.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the images with no bounding boxes\n",
    "keys_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99c22b",
   "metadata": {},
   "source": [
    "# Running craft and saving the segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n",
      "  warnings.warn(\n",
      "/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/242 [00:00<?, ?it/s]/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/craft_text_detector/craft_utils.py:415: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  polys = np.array(polys)\n",
      "/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/craft_text_detector/predict.py:110: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  polys_as_ratio = np.array(polys_as_ratio)\n",
      " 75%|███████▍  | 181/242 [02:49<01:10,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "# initialize the CRAFT model\n",
    "craft = Craft(output_dir = output_dir_craft, \n",
    "              export_extra = False, \n",
    "              text_threshold = .7, \n",
    "              link_threshold = .4, \n",
    "              crop_type=\"poly\", \n",
    "              low_text = .3, \n",
    "              cuda = True)\n",
    "\n",
    "# CRAFT on images to get bounding boxes\n",
    "images = []\n",
    "corrupted_images = []\n",
    "no_segmentations = []\n",
    "boxes = {}\n",
    "count= 0\n",
    "img_name = []\n",
    "box = []\n",
    "file_types = (\".jpg\", \".jpeg\",\".png\")\n",
    "    \n",
    "for filename in tqdm(sorted(label_bboxes.keys())):\n",
    "    image = workdir+filename\n",
    "    try:\n",
    "        img = Image.open(image) \n",
    "        img.verify() # Check that the image is valid\n",
    "        bounding_areas = craft.detect_text(image)\n",
    "        if len(bounding_areas['boxes']): #check that a segmentation was found\n",
    "            images.append(image)\n",
    "            boxes[image] = bounding_areas['boxes']\n",
    "            \n",
    "        else:\n",
    "            no_segmentations.append(image)\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        corrupted_images.append(image)\n",
    "\n",
    "# Save the bounding boxes into a pickle file\n",
    "pickle.dump(boxes, open(save_dir+\"boxes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255c2b3",
   "metadata": {},
   "source": [
    "# Getting all the segmented images into a dataloader, and loading model and processor for trocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf2b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting empty folders, which occurs if some of the images get no segementation from CRAFT\n",
    "root = output_dir_craft\n",
    "folders = list(os.walk(root))[1:]\n",
    "deleted = []\n",
    "for folder in folders:\n",
    "    if not folder[2]:\n",
    "        deleted.append(folder)\n",
    "        os.rmdir(folder[0])\n",
    "        \n",
    "# Setting up the TrOCR model and processor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\") # cache_dir\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n",
    "\n",
    "# Use all available gpus\n",
    "model_gpu= nn.DataParallel(model,list(range(torch.cuda.device_count()))).to(device)\n",
    "\n",
    "# Dataloader for working with gpus\n",
    "trainset = datasets.ImageFolder(output_dir_craft, transform = processor)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=False)\n",
    "\n",
    "# For matching words to image\n",
    "filenames = [s.replace('_crops', '') for s in list(trainset.class_to_idx)]\n",
    "\n",
    "# For matching the image name with the label name\n",
    "word_log_dic = {k: v for k,v in enumerate(filenames)}\n",
    "# For matching the image name with the transriptions\n",
    "words_identified = {k: [] for v,k in enumerate(filenames)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17dc11",
   "metadata": {},
   "source": [
    "# Saving the filenames, word_log_dic and words_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dcb988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filenames\n",
    "with open(save_dir+'filenames.txt', 'w') as fp:\n",
    "    for item in filenames:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "# Save word_log_dic \n",
    "with open(save_dir+'word_log_dic.json', 'w') as fp:\n",
    "    json.dump(word_log_dic, fp)\n",
    "# Save words_identified\n",
    "with open(save_dir+'words_identified.json', 'w') as fp:\n",
    "    json.dump(words_identified, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b47fc7",
   "metadata": {},
   "source": [
    "# Running Tr-OCR on the Segmented Images from Craft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "952d659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing Image Segments: 100%|██████████| 158/158 [02:34<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plants of California</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calaveras. Ranger Station, Stanislaus Forest,</td>\n",
       "      <td>0.483036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avery, Calaveras County.</td>\n",
       "      <td>0.299946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01237442</td>\n",
       "      <td>0.120719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no. 9132</td>\n",
       "      <td>0.391138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Results  Confidence  Labels\n",
       "0                           plants of California    0.000466       0\n",
       "1  Calaveras. Ranger Station, Stanislaus Forest,    0.483036       0\n",
       "2                       Avery, Calaveras County.    0.299946       0\n",
       "3                                       01237442    0.120719       0\n",
       "4                                       no. 9132    0.391138       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Storing the outputs\n",
    "results,confidence,labels = trocr.evaluate_craft_seg(model,processor, words_identified,word_log_dic,testloader,device)\n",
    "#Saving all the outputs in dataframe\n",
    "df = pd.DataFrame(list(zip(results,confidence,labels)),columns = ['Results','Confidence','Labels'])\n",
    "df.to_pickle(save_dir+'full_results.pkl')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6def9a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_Confidence</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Bounding_Boxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[plants of California, Calaveras. Ranger Stati...</td>\n",
       "      <td>[0.0004661529092118144, 0.4830363392829895, 0....</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4427.475, 7904.178], [5505.9624, 7904.178],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Flora Hawaiiansis, Collected by C. N. Forbes ...</td>\n",
       "      <td>[0.040508534759283066, 0.0575096495449543, 9.6...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4610.7188, 7824.25], [5379.172, 7824.25], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Dudley Herbarium of Stanford University, Plan...</td>\n",
       "      <td>[0.31743180751800537, 0.5072717070579529, 0.56...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[2165.2695, 4553.7295], [3353.666, 4544.727]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Elymius hystrix L., det. J.J.N. Campbell - 20...</td>\n",
       "      <td>[0.009591127745807171, 0.9962418079376221]</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4248.603, 6308.9624], [4944.8623, 6308.9624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Flora of Washington, D. c., and vicinity, Buc...</td>\n",
       "      <td>[0.8306760191917419, 0.045502372086048126, 0.0...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4121.703, 7768.3623], [5421.0874, 7768.3623...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                      Transcription  \\\n",
       "0       0  [plants of California, Calaveras. Ranger Stati...   \n",
       "1       1  [Flora Hawaiiansis, Collected by C. N. Forbes ...   \n",
       "2       2  [Dudley Herbarium of Stanford University, Plan...   \n",
       "3       3  [Elymius hystrix L., det. J.J.N. Campbell - 20...   \n",
       "4       4  [Flora of Washington, D. c., and vicinity, Buc...   \n",
       "\n",
       "                            Transcription_Confidence  \\\n",
       "0  [0.0004661529092118144, 0.4830363392829895, 0....   \n",
       "1  [0.040508534759283066, 0.0575096495449543, 9.6...   \n",
       "2  [0.31743180751800537, 0.5072717070579529, 0.56...   \n",
       "3         [0.009591127745807171, 0.9962418079376221]   \n",
       "4  [0.8306760191917419, 0.045502372086048126, 0.0...   \n",
       "\n",
       "                                          Image_Path  \\\n",
       "0  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "1  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "2  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "3  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "4  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "\n",
       "                                      Bounding_Boxes  \n",
       "0  [[[4427.475, 7904.178], [5505.9624, 7904.178],...  \n",
       "1  [[[4610.7188, 7824.25], [5379.172, 7824.25], [...  \n",
       "2  [[[2165.2695, 4553.7295], [3353.666, 4544.727]...  \n",
       "3  [[[4248.603, 6308.9624], [4944.8623, 6308.9624...  \n",
       "4  [[[4121.703, 7768.3623], [5421.0874, 7768.3623...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First part of final csv with results, confidence level from tr-ocr, and label\n",
    "df = pd.read_pickle(save_dir+'full_results.pkl')\n",
    "boxes = pickle.load(open(save_dir+\"boxes.pkl\", \"rb\"))\n",
    "combined_df = trocr.combine_by_label(df)\n",
    "\n",
    "# Adding the image path and all bounding boxes \n",
    "df_dictionary = pd.DataFrame(boxes.items(), columns=['Image_Path', 'Bounding_Boxes'])\n",
    "combined_df = pd.concat([combined_df, df_dictionary], axis=1, join='inner')\n",
    "display(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87f663f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save intermediate file\n",
    "combined_df.to_pickle(save_dir+'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0691febf-f29b-4557-8125-ecf8bed5e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"./combined_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3e4c9",
   "metadata": {},
   "source": [
    "# Reading in the ground truth files for tested images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f74ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the ground truth values\n",
    "\n",
    "gt_t = workdir2+'/taxon_gt.txt'\n",
    "Taxon_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_t, \"r\", encoding=\"utf-8\") }\n",
    "\n",
    "gt_g = workdir2+'/geography_gt.txt'\n",
    "Geography_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_g, \"r\", encoding=\"utf-8\") }\n",
    "\n",
    "gt_c = workdir2+'/collector_gt.txt'\n",
    "Collector_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_c, \"r\", encoding=\"utf-8\") }\n",
    "\n",
    "comparison_file = {\"Taxon\":Taxon_truth,\"Countries\":Geography_truth,\"Collector\":Collector_truth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89201644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1697659851': 'Euphrasia officinalis', '2573258025': 'Bryoerythrophyllum recurvirostrum', '2597666444': 'Carduus tenuiflorus', '1931288980': 'Agoseris parviflora', '1930241969': 'Spiraea canescens', '1929944910': 'Chylismia scapoidea', '1931007576': 'Carex typhina', '1928514234': 'Stachys hispida', '1928658806': 'Solanum donianum', '1931124118': 'Suaeda nigra'}\n"
     ]
    }
   ],
   "source": [
    "Taxon_truth_sample = {k: Taxon_truth[k] for k in list(Taxon_truth)[:10]}\n",
    "\n",
    "# view subset of the taxon truth\n",
    "print(Taxon_truth_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb09b32",
   "metadata": {},
   "source": [
    "# Use TaxoNERD to recognize taxons from detected text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6b0c983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = TaxoNERD(prefer_gpu=False) # set to \"true\" if GPU is accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a636d3e6-95e6-41e8-877c-060b3669ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_md\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "# ! python -m spacy download en_core_web_trf\n",
    "\n",
    "# from numpy.linalg import norm\n",
    "\n",
    "# # Load the spaCy model for date and location recognition\n",
    "# w2v = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# # Convert word to its vector representation\n",
    "# def word2vec(word):\n",
    "#     return w2v(word).vector\n",
    "\n",
    "# # Compute cosine similarity between two word vectors\n",
    "# def cosdis(v1, v2):\n",
    "#     v1_norm = norm(v1)\n",
    "#     v2_norm = norm(v2)\n",
    "#     if v1_norm > 0 and v2_norm > 0:\n",
    "#         return np.dot(v1, v2) / (v1_norm * v2_norm)\n",
    "#     else:\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3ee7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for finding cosine similarity\n",
    "\n",
    "def word2vec(word):\n",
    "    from collections import Counter\n",
    "    from math import sqrt\n",
    "\n",
    "    # count the characters in word\n",
    "    cw = Counter(word)\n",
    "    # precomputes a set of the different characters\n",
    "    sw = set(cw)\n",
    "    # precomputes the \"length\" of the word vector\n",
    "    lw = sqrt(sum(c*c for c in cw.values()))\n",
    "\n",
    "    # return a tuple\n",
    "    return cw, sw, lw\n",
    "\n",
    "def cosdis(v1, v2):\n",
    "    # which characters are common to the two words?\n",
    "    common = v1[1].intersection(v2[1])\n",
    "    # by definition of cosine distance we have\n",
    "    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "007a01f8-37e7-41e9-a16a-fc4e3919b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projectnb/sparkgrp/ml-herbarium-grp/summer2023/kabilanm/ml-herbarium/trocr'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify cache folder for taxonnerd (I changed the module codebase)\n",
    "os.environ['TAXONERD_CACHE']='/projectnb/sparkgrp/ml-herbarium-grp/summer2023/kabilanm/ml-herbarium/trocr'\n",
    "os.getenv(\"TAXONERD_CACHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ccdd1ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nmslib:Loading index from /projectnb/sparkgrp/ml-herbarium-grp/summer2023/kabilanm/ml-herbarium/trocr/datasets/bdb932a2c23507c7fb54dd2eff1ca3ac71005d9913e22542bb87ff92405076e5.nmslib_index.bin\n",
      "INFO:nmslib:Loading regular index.\n",
      "INFO:nmslib:Finished loading index\n",
      "INFO:nmslib:Set HNSW query-time parameters:\n",
      "INFO:nmslib:ef(Search)         =20\n",
      "INFO:nmslib:algoType           =2\n",
      "INFO:nmslib:Set HNSW query-time parameters:\n",
      "INFO:nmslib:ef(Search)         =200\n",
      "INFO:nmslib:algoType           =2\n"
     ]
    }
   ],
   "source": [
    "# ! pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.0/en_core_eco_md-1.0.2.tar.gz\n",
    "\n",
    "nlp = ner.load(\n",
    "    model=\"en_core_eco_md\", # en_core_eco_md\n",
    "    linker=\"gbif_backbone\",\n",
    "    threshold=0 # we set the threshold to \"0\" so that we can collate results at various threasholds later\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "34b4f810-de9e-44e2-a120-4bffe7095579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a transformer model from spaCy for person and location information\n",
    "nlp_loc = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "803900b2-997c-4ded-ac62-0ac21479824b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataframe from CSV file saved previously\n",
    "combined_df = pd.read_csv(\"./combined_df.csv\", index_col=0)\n",
    "combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a98893c4-ac20-4d73-8b58-c19f02f6f8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_Confidence</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Bounding_Boxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['plants of California', 'Calaveras. Ranger St...</td>\n",
       "      <td>[0.0004661529092118144, 0.4830363392829895, 0....</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4427.475  7904.178 ]\\n  [5505.9624 7904.178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Flora Hawaiiansis', 'Collected by C. N. Forb...</td>\n",
       "      <td>[0.040508534759283066, 0.0575096495449543, 9.6...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4610.7188 7824.25  ]\\n  [5379.172  7824.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Dudley Herbarium of Stanford University', 'P...</td>\n",
       "      <td>[0.31743180751800537, 0.5072717070579529, 0.56...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[2165.2695 4553.7295]\\n  [3353.666  4544.727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['Elymius hystrix L.', 'det. J.J.N. Campbell -...</td>\n",
       "      <td>[0.009591127745807171, 0.9962418079376221]</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4248.603  6308.9624]\\n  [4944.8623 6308.962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Flora of Washington, D. c., and vicinity', '...</td>\n",
       "      <td>[0.8306760191917419, 0.045502372086048126, 0.0...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4121.703  7768.3623]\\n  [5421.0874 7768.362...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                      Transcription  \\\n",
       "0       0  ['plants of California', 'Calaveras. Ranger St...   \n",
       "1       1  ['Flora Hawaiiansis', 'Collected by C. N. Forb...   \n",
       "2       2  ['Dudley Herbarium of Stanford University', 'P...   \n",
       "3       3  ['Elymius hystrix L.', 'det. J.J.N. Campbell -...   \n",
       "4       4  ['Flora of Washington, D. c., and vicinity', '...   \n",
       "\n",
       "                            Transcription_Confidence  \\\n",
       "0  [0.0004661529092118144, 0.4830363392829895, 0....   \n",
       "1  [0.040508534759283066, 0.0575096495449543, 9.6...   \n",
       "2  [0.31743180751800537, 0.5072717070579529, 0.56...   \n",
       "3         [0.009591127745807171, 0.9962418079376221]   \n",
       "4  [0.8306760191917419, 0.045502372086048126, 0.0...   \n",
       "\n",
       "                                          Image_Path  \\\n",
       "0  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "1  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "2  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "3  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "4  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "\n",
       "                                      Bounding_Boxes  \n",
       "0  [[[4427.475  7904.178 ]\\n  [5505.9624 7904.178...  \n",
       "1  [[[4610.7188 7824.25  ]\\n  [5379.172  7824.25 ...  \n",
       "2  [[[2165.2695 4553.7295]\\n  [3353.666  4544.727...  \n",
       "3  [[[4248.603  6308.9624]\\n  [4944.8623 6308.962...  \n",
       "4  [[[4121.703  7768.3623]\\n  [5421.0874 7768.362...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that the dataframe has been read correctly\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0f116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use TaxoNERD for entity recognition and linking against the GBIF database\n",
    "\n",
    "taxon_output = []\n",
    "location_output = []\n",
    "confidence_output = []\n",
    "\n",
    "# predict taxons for text detected from each image\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "    # Convert the strings in the 'list_column' to actual lists\n",
    "    temp = ast.literal_eval(row[\"Transcription\"])\n",
    "\n",
    "    # construct a single string out of all the detected text\n",
    "    input_text = \" \".join(temp)\n",
    "    doc = ner.find_in_text(input_text)\n",
    "    entities = []\n",
    "\n",
    "    if(input_text == \"\"):\n",
    "        taxon_output.append(\"\")\n",
    "        confidence_output.append(float(0))\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # append linked taxon entity with the highest confidence\n",
    "        for entity in doc.entity:\n",
    "            entities.append(entity[0])\n",
    "\n",
    "        result = max(entities, key=lambda x: x[2])        \n",
    "        taxon_output.append(str(result[1]))\n",
    "        confidence_output.append(float(result[2]))\n",
    "\n",
    "    except AttributeError:\n",
    "        # append empty strings when no entity is detected\n",
    "        taxon_output.append(\"\")\n",
    "        confidence_output.append(float(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c452f06-71f5-454d-91a9-ac86f06133a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spaCy model to recognize date and location from the text\n",
    "\n",
    "location_output = []\n",
    "date_output = []\n",
    "\n",
    "# predict taxons for text detected from each image\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "    # Convert the strings in the 'list_column' to actual lists\n",
    "    temp = ast.literal_eval(row[\"Transcription\"])\n",
    "\n",
    "    # construct a single string out of all the detected text\n",
    "    input_text = \" \".join(temp)\n",
    "    doc_loc = nlp_loc(input_text)\n",
    "    entities = []\n",
    "    loc_entities = []\n",
    "    date_entities = []\n",
    "\n",
    "    if(input_text == \"\"):\n",
    "        location_output.append(\"\")\n",
    "        date_output.append(\"\")\n",
    "        continue\n",
    "\n",
    "# append location and date entities recognized in the text\n",
    "    for ent in doc_loc.ents:\n",
    "        if(ent.label_ == \"LOC\"): \n",
    "            loc_entities.append(ent.text)\n",
    "        if(ent.label_ == \"DATE\"):\n",
    "            date_entities.append(ent.text)\n",
    "    # print(loc_entities, date_entities)\n",
    "\n",
    "# Need to group the locations and dates found based on the label they were found in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d947b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predicted taxon and confidence scores to the dataframe\n",
    "combined_df[\"Taxon_Output\"] = taxon_output\n",
    "combined_df[\"Confidence_Output\"] = confidence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9641e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_Confidence</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Bounding_Boxes</th>\n",
       "      <th>Taxon_Output</th>\n",
       "      <th>Confidence_Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['plants of California', 'Calaveras. Ranger St...</td>\n",
       "      <td>[0.0004661529092118144, 0.4830363392829895, 0....</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4427.475  7904.178 ]\\n  [5505.9624 7904.178...</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Flora Hawaiiansis', 'Collected by C. N. Forb...</td>\n",
       "      <td>[0.040508534759283066, 0.0575096495449543, 9.6...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4610.7188 7824.25  ]\\n  [5379.172  7824.25 ...</td>\n",
       "      <td>Clermontia persicifolia</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Dudley Herbarium of Stanford University', 'P...</td>\n",
       "      <td>[0.31743180751800537, 0.5072717070579529, 0.56...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[2165.2695 4553.7295]\\n  [3353.666  4544.727...</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['Elymius hystrix L.', 'det. J.J.N. Campbell -...</td>\n",
       "      <td>[0.009591127745807171, 0.9962418079376221]</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4248.603  6308.9624]\\n  [4944.8623 6308.962...</td>\n",
       "      <td>Elymus hystrix hystrix</td>\n",
       "      <td>0.777422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Flora of Washington, D. c., and vicinity', '...</td>\n",
       "      <td>[0.8306760191917419, 0.045502372086048126, 0.0...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/summer202...</td>\n",
       "      <td>[[[4121.703  7768.3623]\\n  [5421.0874 7768.362...</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                      Transcription  \\\n",
       "0       0  ['plants of California', 'Calaveras. Ranger St...   \n",
       "1       1  ['Flora Hawaiiansis', 'Collected by C. N. Forb...   \n",
       "2       2  ['Dudley Herbarium of Stanford University', 'P...   \n",
       "3       3  ['Elymius hystrix L.', 'det. J.J.N. Campbell -...   \n",
       "4       4  ['Flora of Washington, D. c., and vicinity', '...   \n",
       "\n",
       "                            Transcription_Confidence  \\\n",
       "0  [0.0004661529092118144, 0.4830363392829895, 0....   \n",
       "1  [0.040508534759283066, 0.0575096495449543, 9.6...   \n",
       "2  [0.31743180751800537, 0.5072717070579529, 0.56...   \n",
       "3         [0.009591127745807171, 0.9962418079376221]   \n",
       "4  [0.8306760191917419, 0.045502372086048126, 0.0...   \n",
       "\n",
       "                                          Image_Path  \\\n",
       "0  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "1  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "2  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "3  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "4  /projectnb/sparkgrp/ml-herbarium-grp/summer202...   \n",
       "\n",
       "                                      Bounding_Boxes             Taxon_Output  \\\n",
       "0  [[[4427.475  7904.178 ]\\n  [5505.9624 7904.178...                            \n",
       "1  [[[4610.7188 7824.25  ]\\n  [5379.172  7824.25 ...  Clermontia persicifolia   \n",
       "2  [[[2165.2695 4553.7295]\\n  [3353.666  4544.727...                            \n",
       "3  [[[4248.603  6308.9624]\\n  [4944.8623 6308.962...   Elymus hystrix hystrix   \n",
       "4  [[[4121.703  7768.3623]\\n  [5421.0874 7768.362...                            \n",
       "\n",
       "   Confidence_Output  \n",
       "0           0.000000  \n",
       "1           1.000000  \n",
       "2           0.000000  \n",
       "3           0.777422  \n",
       "4           0.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6769c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pickle.read()\n",
    "# array to store computed similarity scores\n",
    "cosine_sim = []\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "\n",
    "    # extract image name from the dataframe\n",
    "    img_name = row[\"Image_Path\"].split(\"/\")[-1][:-4]\n",
    "    taxon_predicted = row[\"Taxon_Output\"]\n",
    "    taxon_gt = Taxon_truth[img_name]\n",
    "\n",
    "    # print(f\"Image: {img_name}, Predicted: {taxon_predicted}, Truth: {taxon_gt}\")\n",
    "\n",
    "    # compute cosine similarity between the predicted taxon and ground truth\n",
    "    try:\n",
    "        sim = cosdis(word2vec(taxon_gt), word2vec(taxon_predicted))\n",
    "        cosine_sim.append(sim)\n",
    "        # print(taxon_gt, taxon_predicted, sim)\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        cosine_sim.append(0)\n",
    "        # print(taxon_gt, taxon_predicted,\"0\")\n",
    "\n",
    "# append similarity scores to the dataframe\n",
    "combined_df[\"Cosine_Similarity\"] = cosine_sim\n",
    "combined_df.to_pickle(save_dir+\"full_results_with_cossim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7d8b3ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confidence_Threshold</th>\n",
       "      <th>Num_Taxons_Correct</th>\n",
       "      <th>Num_Taxons_Total</th>\n",
       "      <th>Taxons_Accuracy_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.396694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.608974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.640845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>83.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.658730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.690722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Confidence_Threshold  Num_Taxons_Correct  Num_Taxons_Total  \\\n",
       "0                    0.0                96.0             242.0   \n",
       "1                    0.1                96.0             168.0   \n",
       "2                    0.2                96.0             168.0   \n",
       "3                    0.3                96.0             168.0   \n",
       "4                    0.4                96.0             168.0   \n",
       "5                    0.5                95.0             156.0   \n",
       "6                    0.6                91.0             142.0   \n",
       "7                    0.7                83.0             126.0   \n",
       "8                    0.8                67.0              97.0   \n",
       "9                    0.9                39.0              58.0   \n",
       "10                   1.0                27.0              37.0   \n",
       "\n",
       "    Taxons_Accuracy_Predicted  \n",
       "0                    0.396694  \n",
       "1                    0.571429  \n",
       "2                    0.571429  \n",
       "3                    0.571429  \n",
       "4                    0.571429  \n",
       "5                    0.608974  \n",
       "6                    0.640845  \n",
       "7                    0.658730  \n",
       "8                    0.690722  \n",
       "9                    0.672414  \n",
       "10                   0.729730  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_df = pickle.load(open(save_dir+\"full_results_with_cossim.pkl\", \"rb\"))\n",
    "final_taxon_prediction = pd.DataFrame(columns=[\"Confidence_Threshold\", \"Num_Taxons_Correct\", \n",
    "                                               \"Num_Taxons_Total\", \"Taxons_Accuracy_Predicted\"])\n",
    "temp_df = pd.DataFrame()\n",
    "\n",
    "# generate list of similarity thresholds\n",
    "# sim_threshold = [0.9]\n",
    "sim_threshold = 0.8\n",
    "\n",
    "# generate list of confidence thresholds\n",
    "confidence_threshold = np.arange(0, 1.001, 0.1)\n",
    "\n",
    "# compute prediction accuracy at each confidence threshold\n",
    "for conf_threshold in confidence_threshold:\n",
    "    \n",
    "    temp_df = combined_df[(combined_df[\"Confidence_Output\"] >= conf_threshold)]\n",
    "    # print(len(temp_df))\n",
    "    \n",
    "    acc_count = (temp_df[\"Cosine_Similarity\"] >= sim_threshold).sum()\n",
    "\n",
    "    acc_value = acc_count/len(temp_df)\n",
    "\n",
    "    temp = [conf_threshold, acc_count, len(temp_df), acc_value]\n",
    "    final_taxon_prediction.loc[len(final_taxon_prediction)] = temp\n",
    "\n",
    "display(final_taxon_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df36a9",
   "metadata": {},
   "source": [
    "1. We first obtain the taxon predictions with a confidence score for each taxon.\n",
    "2. We then compute cosine similarities of the predicted taxons with the ground truth taxons.\n",
    "3. We then, at each interval of the confidence threashold, compute number of taxons that have a high cosine similarity with the ground truth. The scores above are computed for a specific cosine similarity score \">0.8\". We need to perform this step because, the taxons are matched against entries from the `gbif_backbone` database (as part of TaxoNERD) and, the predicted taxon might not exactly match the ground truth and we are accounting for this using cosine similarity.\n",
    "\n",
    "We can try to use the GBIF database to predict taxons and also experiment with different thresholds for the cosine similarity scores. But, in general, the chosen cosine similarity threshold offers an incremental performance upgrade compared to the last semester's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82905a4a-ecf5-415d-ad02-ebb774e3989a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1084cc30a0beff5f5a336ac1440c1980742df576b417f0ade42be5b6e50918a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

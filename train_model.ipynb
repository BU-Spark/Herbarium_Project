{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install python-Levenshtein\n",
    "import Levenshtein as levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import wget\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn, rnn\n",
    "from mxnet.gluon.data import ArrayDataset, DataLoader\n",
    "import string\n",
    "import tarfile\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from skimage import transform as skimage_tf\n",
    "from skimage import exposure\n",
    "np.seterr(all='raise')\n",
    "\n",
    "import multiprocessing\n",
    "mx.random.seed(1)\n",
    "from mxboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre Processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images =  791\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "import os\n",
    "import PIL\n",
    "import pathlib\n",
    "\n",
    "image_dir = \"/restricted/projectnb/cs501t2/minglan/words/\"\n",
    "\n",
    "image_dir = pathlib.Path(image_dir) \n",
    "image_count = len(list(image_dir.glob('*.png')))\n",
    "print(\"Total number of images = \", image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_IMAGE_SIZE_WORD = (60, 800)\n",
    "def resize_image(image, desired_size):\n",
    "    ''' Helper function to resize an image while keeping the aspect ratio.\n",
    "    Parameter\n",
    "    ---------\n",
    "    \n",
    "    image: np.array\n",
    "        The image to be resized.\n",
    "    desired_size: (int, int)\n",
    "        The (height, width) of the resized image\n",
    "    Return\n",
    "    ------\n",
    "    image: np.array\n",
    "        The image of size = desired_size\n",
    "    bounding box: (int, int, int, int)\n",
    "        (x, y, w, h) in percentages of the resized image of the original\n",
    "    '''\n",
    "    size = image.shape[:2]\n",
    "    if size[0] > desired_size[0] or size[1] > desired_size[1]:\n",
    "        ratio_w = float(desired_size[0])/size[0]\n",
    "        ratio_h = float(desired_size[1])/size[1]\n",
    "        ratio = min(ratio_w, ratio_h)\n",
    "        new_size = tuple([int(x*ratio) for x in size])\n",
    "        image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "        size = image.shape\n",
    "            \n",
    "    delta_w = max(0, desired_size[1] - size[1])\n",
    "    delta_h = max(0, desired_size[0] - size[0])\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "            \n",
    "    color = image[0][0]\n",
    "    if color < 230:\n",
    "        color = 230\n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=float(color))\n",
    "    crop_bb = (left/image.shape[1], top/image.shape[0], (image.shape[1] - right - left)/image.shape[1],\n",
    "               (image.shape[0] - bottom - top)/image.shape[0])\n",
    "    return image, crop_bb\n",
    "\n",
    "def _pre_process_image(img_in):\n",
    "    im = cv2.imread(img_in, cv2.IMREAD_GRAYSCALE)\n",
    "    if np.size(im) == 1: # skip if the image data is corrupt.\n",
    "        return None\n",
    "    # reduce the size of form images so that it can fit in memory.\n",
    "    im, _ = resize_image(im, MAX_IMAGE_SIZE_WORD)\n",
    "    img_arr = np.asarray(im)\n",
    "    return img_arr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data import dataset\n",
    "\n",
    "image_data_file_name = \"image_data-word-text-word.plk\"\n",
    "DATA_FOLDER = \"/restricted/projectnb/cs501t2/minglan/words/\"\n",
    "images_names = []\n",
    "error_count = 0\n",
    "#     image_files = glob.glob(DATA_FOLDER + '/**/*.png', recursive=True)\n",
    "image_files = glob.glob(DATA_FOLDER + '*.png')\n",
    "for filepath in image_files:\n",
    "    try:\n",
    "        images_names.append(filepath.split('/')[-1].split('.')[0])\n",
    "    except:\n",
    "        error_count += 1\n",
    "random.shuffle(images_names)\n",
    "split = 0.8\n",
    "train_subjects = images_names[:int(split*len(images_names))]\n",
    "test_subjects = images_names[int(split*len(images_names)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDataSet(dataset.ArrayDataset):\n",
    "    def __init__(self, train=True): \n",
    "        images_data = []\n",
    "        f = open('/restricted/projectnb/cs501t2/minglan/words.txt')\n",
    "        for line in f:\n",
    "            if not line or line[0] == '#':\n",
    "                continue\n",
    "            lineSplit = line.strip().split(' ')\n",
    "            assert len(lineSplit) >= 9\n",
    "            tmp_id = lineSplit[0]\n",
    "            image_filename = os.path.join(DATA_FOLDER, tmp_id + \".png\")\n",
    "#             print(\"image_filename: \" + image_filename)\n",
    "            image_arr = _pre_process_image(image_filename)\n",
    "            output_data = []\n",
    "            output_data.append(' '.join(lineSplit[8:]))\n",
    "            if image_arr is None:\n",
    "                continue\n",
    "            images_data.append([tmp_id, image_arr, output_data])\n",
    "        \n",
    "        #images_data[lineSplit[0]].append(' '.join(lineSplit[8:]))\n",
    "        images_data = pd.DataFrame(images_data, columns=[\"subject\", \"image\", \"output\"])\n",
    "        images_data.to_pickle(image_data_file_name, protocol=2)\n",
    "        train_data = images_data[np.in1d(images_data[\"subject\"], train_subjects)]\n",
    "        test_data = images_data[np.in1d(images_data[\"subject\"], test_subjects)]\n",
    "        if train: \n",
    "#             print(train_data.shape)\n",
    "            super(IAMDataSet, self).__init__(train_data)\n",
    "        else: \n",
    "            super(IAMDataSet, self).__init__(test_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self._data[0].iloc[idx].image, self._data[0].iloc[idx].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 32\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform(image, label):\n",
    "#     image = np.expand_dims(image, axis=0).astype(np.float32)/255.\n",
    "#     label_encoded = np.zeros(SEQ_LEN, dtype=np.float32)-1\n",
    "#     for i, letter in enumerate(label[0]):\n",
    "#         if i >= SEQ_LEN:\n",
    "#             break\n",
    "#         label_encoded[i] = alphabet_dict[letter]\n",
    "    \n",
    "#     return image, label_encoded\n",
    "def transform(image, label):\n",
    "    '''\n",
    "    This function resizes the input image and converts so that it could be fed into the network.\n",
    "    Furthermore, the label (text) is one-hot encoded.\n",
    "    '''\n",
    "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "    if image[0, 0, 0] > 1:\n",
    "        image = image/255.\n",
    "    image = (image - 0.942532484060557) / 0.15926149044640417\n",
    "    label_encoded = np.zeros(max_seq_len, dtype=np.float32)-1\n",
    "    i = 0\n",
    "    for word in label:\n",
    "        word = word.replace(\"&quot\", r'\"')\n",
    "        word = word.replace(\"&amp\", r'&')\n",
    "        for letter in word:\n",
    "            label_encoded[i] = alphabet_dict[letter]\n",
    "            i += 1\n",
    "    return image, label_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mxboard in /usr4/cs542/mzheng27/.local/lib/python3.7/site-packages (0.1.0)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /share/pkg.7/python3/3.7.9/install/lib/python3.7/site-packages (from mxboard) (3.13.0)\n",
      "Requirement already satisfied: six in /share/pkg.7/python3/3.7.9/install/lib/python3.7/site-packages (from mxboard) (1.15.0)\n",
      "Requirement already satisfied: numpy in /share/pkg.7/python3/3.7.9/install/lib/python3.7/site-packages/numpy-1.19.2-py3.7-linux-x86_64.egg (from mxboard) (1.19.2)\n",
      "Requirement already satisfied: Pillow in /share/pkg.7/python3/3.7.9/install/lib/python3.7/site-packages (from mxboard) (8.0.1)\n",
      "Requirement already satisfied: setuptools in /share/pkg.7/python3/3.7.9/install/lib/python3.7/site-packages (from protobuf>=3.0.0->mxboard) (50.3.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.7.9/install/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mxboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr.handwriting_line_recognition import Network as HandwritingRecognitionNet, handwriting_recognition_transform\n",
    "from ocr.handwriting_line_recognition import decode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_encoding = r' !\"#&\\'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "alphabet_dict = {alphabet_encoding[i]:i for i in range(len(alphabet_encoding))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/restricted/projectnb/cs501t2/minglan/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "lr_period = 30\n",
    "lr_scale  = 1\n",
    "print_every_n = 5\n",
    "save_every_n = 10\n",
    "send_image_every_n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(e, network, dataloader, trainer, log_dir, print_name, update_network, save_network):\n",
    "    total_loss = nd.zeros(1, ctx)\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        x = x.as_in_context(ctx)\n",
    "#         print(x)\n",
    "        y = y.as_in_context(ctx)\n",
    "#         print(y)\n",
    "        with autograd.record():\n",
    "            output = network(x)\n",
    "            loss_ctc = ctc_loss(output, y)\n",
    "\n",
    "        if update_network:\n",
    "            loss_ctc.backward()\n",
    "            trainer.step(x.shape[0])\n",
    "        \n",
    "        if i == 0 and e % send_image_every_n == 0 and e > 0:\n",
    "            predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "            decoded_text = decode(predictions)\n",
    "            image = x.asnumpy()\n",
    "            image = image * 0.15926149044640417 + 0.942532484060557            \n",
    "            output_image = draw_text_on_image(image, decoded_text)\n",
    "            print(\"{} first decoded text = {}\".format(print_name, decoded_text[0]))\n",
    "            with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "                sw.add_image('bb_{}_image'.format(print_name), output_image, global_step=e)\n",
    "        nd.waitall()\n",
    "\n",
    "        total_loss += loss_ctc.mean()\n",
    "\n",
    "    epoch_loss = float(total_loss.asscalar())/len(dataloader)\n",
    "\n",
    "    with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "        sw.add_scalar('loss', {print_name: epoch_loss}, global_step=e)\n",
    "\n",
    "    if save_network and e % save_every_n == 0 and e > 0:\n",
    "        network.save_params(\"{}/{}\".format(checkpoint_dir, checkpoint_name))\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_transform(image, label):\n",
    "    '''\n",
    "    This function randomly:\n",
    "        - translates the input image by +-width_range and +-height_range (percentage).\n",
    "        - scales the image by y_scaling and x_scaling (percentage)\n",
    "        - shears the image by shearing_factor (radians)\n",
    "    '''\n",
    "\n",
    "    ty = random.uniform(-random_y_translation, random_y_translation)\n",
    "    tx = random.uniform(-random_x_translation, random_x_translation)\n",
    "\n",
    "    sx = random.uniform(1. - random_y_scaling, 1. + random_y_scaling)\n",
    "    sy = random.uniform(1. - random_x_scaling, 1. + random_x_scaling)\n",
    "\n",
    "    s = random.uniform(-random_shearing, random_shearing)\n",
    "\n",
    "    st = skimage_tf.AffineTransform(scale=(sx, sy),\n",
    "                                    shear=s,\n",
    "                                    translation=(tx*image.shape[1], ty*image.shape[0]))\n",
    "    augmented_image = skimage_tf.warp(image, st, cval=1.0)\n",
    "    return transform(augmented_image*255., label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text_on_image(images, text):\n",
    "    output_image_shape = (images.shape[0], images.shape[1], images.shape[2] * 2, images.shape[3])  # Double the output_image_shape to print the text in the bottom\n",
    "    \n",
    "    output_images = np.zeros(shape=output_image_shape)\n",
    "    for i in range(images.shape[0]):\n",
    "        white_image_shape = (images.shape[2], images.shape[3])\n",
    "        white_image = np.ones(shape=white_image_shape)*1.0\n",
    "        text_image = cv2.putText(white_image, text[i], org=(5, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=0.0, thickness=1)\n",
    "        output_images[i, :, :images.shape[2], :] = images[i]\n",
    "        output_images[i, :, images.shape[2]:, :] = text_image\n",
    "    return output_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 632\n",
      "Number of testing samples: 159\n"
     ]
    }
   ],
   "source": [
    "train_ds = IAMDataSet(train=True)\n",
    "print(\"Number of training samples: {}\".format(len(train_ds)))\n",
    "test_ds = IAMDataSet(train=False)\n",
    "print(\"Number of testing samples: {}\".format(len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[234, 234, 234, ..., 234, 234, 234],\n",
       "        [234, 234, 234, ..., 234, 234, 234],\n",
       "        [234, 234, 234, ..., 234, 234, 234],\n",
       "        ...,\n",
       "        [234, 234, 234, ..., 234, 234, 234],\n",
       "        [234, 234, 234, ..., 234, 234, 234],\n",
       "        [234, 234, 234, ..., 234, 234, 234]], dtype=uint8),\n",
       " ['Actinidia arguta'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(train_ds.transform(augment_transform), BATCH_SIZE, shuffle=True, last_batch=\"discard\")\n",
    "test_data = gluon.data.DataLoader(test_ds.transform(transform), BATCH_SIZE, shuffle=False, last_batch=\"discard\")#, num_workers=4)\n",
    "\n",
    "random_x_translation = 0.03\n",
    "random_y_translation = 0.03\n",
    "random_x_scaling = 0.10\n",
    "random_y_scaling = 0.1\n",
    "random_shearing = 0.5\n",
    "max_seq_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_data:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HandwritingRecognitionNet(rnn_hidden_states=512,rnn_layers=2, ctx=ctx, max_seq_len=160)\n",
    "net.load_parameters(\"models/handwriting_line8.params\", ctx=ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = \"handwriting_line.params\"\n",
    "schedule = mx.lr_scheduler.FactorScheduler(step=lr_period, factor=lr_scale)\n",
    "schedule.base_lr = learning_rate\n",
    "ctc_loss = gluon.loss.CTCLoss()\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate, \"lr_scheduler\": schedule, 'clip_gradient': 2})\n",
    "log_dir = \"/restricted/projectnb/cs501t2/minglan/logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train_loss 25.722319, test_loss 28.950094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/mxnet/1.7.0/install/lib/SCC/../python3.7-gpu/site-packages/mxnet/gluon/block.py:462: UserWarning: save_params is deprecated. Please use save_parameters. Note that if you want load from SymbolBlock later, please use export instead. For details, see https://mxnet.apache.org/tutorials/gluon/save_load_params.html\n",
      "  warnings.warn(\"save_params is deprecated. Please use save_parameters. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train_loss 19.672482, test_loss 23.387917\n",
      "Epoch 15, train_loss 16.453188, test_loss 20.461409\n",
      "train first decoded text = Alllim schoenoprasu\n",
      "test first decoded text = Sambucus canadensis\n",
      "Epoch 20, train_loss 13.743091, test_loss 18.498945\n",
      "Epoch 25, train_loss 12.061693, test_loss 17.425346\n",
      "Epoch 30, train_loss 10.484405, test_loss 16.719978\n",
      "Epoch 35, train_loss 9.373567, test_loss 16.035009\n",
      "train first decoded text = solidags\n",
      "test first decoded text = Sambucus Canadensis\n",
      "Epoch 40, train_loss 8.192978, test_loss 15.498623\n",
      "Epoch 45, train_loss 7.541565, test_loss 14.908926\n",
      "Epoch 50, train_loss 6.673493, test_loss 14.948702\n",
      "Epoch 55, train_loss 6.249042, test_loss 14.783789\n",
      "train first decoded text = Ace\n",
      "test first decoded text = Sambucus canadensis\n",
      "Epoch 60, train_loss 5.515146, test_loss 14.644998\n",
      "Epoch 65, train_loss 4.871694, test_loss 14.868935\n",
      "Epoch 70, train_loss 3.992592, test_loss 14.576623\n",
      "Epoch 75, train_loss 3.951075, test_loss 14.516824\n",
      "train first decoded text = ambrosia\n",
      "test first decoded text = Sambucus canadensis\n",
      "Epoch 80, train_loss 3.451101, test_loss 14.402529\n",
      "Epoch 85, train_loss 3.163371, test_loss 14.301523\n",
      "Epoch 90, train_loss 2.862275, test_loss 14.527157\n",
      "Epoch 95, train_loss 2.487466, test_loss 14.649778\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "for e in range(epochs):\n",
    "    train_loss = run_epoch(e, net, train_data, trainer, log_dir, print_name=\"train\", update_network=True, save_network=True)\n",
    "    test_loss = run_epoch(e, net, test_data, trainer, log_dir, print_name=\"test\", \\\n",
    "                          update_network=False, save_network=False)\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "    if e % print_every_n == 0 and e > 0:\n",
    "        print(\"Epoch {0}, train_loss {1:.6f}, test_loss {2:.6f}\".format(e, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ad6ebc6ae10>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_train)\n",
    "plt.plot(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
